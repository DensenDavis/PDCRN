{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DWT_Normal_POLED.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bbW39HTF9GO",
        "colab_type": "text"
      },
      "source": [
        "# Designed to run in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPhdvEPGH-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This program is designed to run in Colab (yes, we are skipping the req file)\n",
        "# The code is about as unstructured and inefficient as it gets, but hey, it works...... umm...probably !!  :)\n",
        "# For further details, please refer our paper 'Transform Domain Pyramidal Dilated Convolution Networks For Restoration of Under Display Camera Images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4m40Fa7dJ1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8s-XpAZzOTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tensorlayer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E0zYPS7f82z",
        "colab_type": "text"
      },
      "source": [
        "# ImportPackages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOz9UuM6dIas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import imageio\n",
        "import numpy as np\n",
        "import tensorlayer as tl\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import Conv2D, Input, Conv2DTranspose, Concatenate, Add, Lambda\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjIqo7u7gBLW",
        "colab_type": "text"
      },
      "source": [
        "# Set Training Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5db_TcOodMXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Defaults\n",
        "class Configuration:\n",
        "  png_data = '/content/drive/My Drive/udc/DATASET/POLED/train/'   # png_data (training) should contain 2 folders : 1. gt and 2. input. The gt & input images should be placed in these folders with matching names\n",
        "  base_dir = '/content/drive/My Drive/udc/DWT_POLED/'  # Base directory for the program.\n",
        "  save_image_dir = base_dir+'images'\n",
        "  save_model_dir = base_dir+'models'\n",
        "  log_dir = base_dir+'log'\n",
        "  steps_total=None\n",
        "  batch_shape = (10,512,512,3)\n",
        "  weight_mse_loss = 1\n",
        "  weight_char_loss = 1\n",
        "  progress_freq = 10        # Interval at which training progress is displayed. Choose a high value if running on colab to prevent the system from getting stuck\n",
        "  display_freq = 50         # Interval at which sample predictions are generated in base_dir/images/epoch\n",
        "  plot_training_freq = 20   # Interval at which training plots are generated in base_dir/log\n",
        "  display_samples = 5       # Number of sample predictions for at display interval. This value will also depend on batch_shape and total training examples, so display_samples is not always correct\n",
        "\n",
        "config = Configuration()\n",
        "tf.io.gfile.makedirs(config.save_model_dir)\n",
        "tf.io.gfile.makedirs(config.save_image_dir)\n",
        "tf.io.gfile.makedirs(config.log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FNSmttngFM4",
        "colab_type": "text"
      },
      "source": [
        "# Set Testing Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XtqFv3QdPSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestConfiguration:\n",
        "  png_data = '/content/drive/My Drive/udc/DATASET/POLED/validation/'  # png_data (validation )should contain 2 folders : 1. gt and 2. input. The gt & input images should be placed in these folders with matching names\n",
        "  batch_shape = (1,1024,None,3)  # for RLQ-TOD 2020 udc dataset image height is fixed at 1024\n",
        "  file_count = None\n",
        "Tconfig = TestConfiguration()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoU0-jMHgIOv",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO9doZhmpvvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gt = sorted(tl.files.load_file_list(path=config.png_data+'gt/', regx='.*.png', printable=False))\n",
        "train_gt = tl.vis.read_images(train_gt, path=config.png_data+'gt/', n_threads=64)\n",
        "train_input = sorted(tl.files.load_file_list(path=config.png_data+'input/', regx='.*.png', printable=False))\n",
        "train_input = tl.vis.read_images(train_input, path=config.png_data+'input/', n_threads=64)\n",
        "test_gt = sorted(tl.files.load_file_list(path=Tconfig.png_data+'gt/', regx='.*.png', printable=False))\n",
        "test_gt = tl.vis.read_images(test_gt, path=Tconfig.png_data+'gt/', n_threads=10)\n",
        "test_input = sorted(tl.files.load_file_list(path=Tconfig.png_data+'input/', regx='.*.png', printable=False))\n",
        "test_input = tl.vis.read_images(test_input, path=Tconfig.png_data+'input/', n_threads=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USGqf-2bX1F3",
        "colab_type": "text"
      },
      "source": [
        "# Create Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svshX86Ep6o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell will change drastically in a future update\n",
        "def get_train_data():\n",
        "  def hq_train():\n",
        "      for img in train_gt:\n",
        "          yield img\n",
        "  def lq_train():\n",
        "    for img in test_gt:\n",
        "      yield img\n",
        "  def random_crop(lq_img, hq_img, hq_crop_size=config.batch_shape[1], scale=1):\n",
        "      lq_crop_size = hq_crop_size // scale\n",
        "      lq_img_shape = tf.shape(lq_img)[:2]\n",
        "      lq_w = tf.random.uniform(shape=(), maxval=lq_img_shape[1] - lq_crop_size + 1, dtype=tf.int32)\n",
        "      lq_h = tf.random.uniform(shape=(), maxval=lq_img_shape[0] - lq_crop_size + 1, dtype=tf.int32)\n",
        "\n",
        "      hq_w = lq_w * scale\n",
        "      hq_h = lq_h * scale\n",
        "\n",
        "      lq_img_cropped = lq_img[lq_h:lq_h + lq_crop_size, lq_w:lq_w + lq_crop_size]\n",
        "      hq_img_cropped = hq_img[hq_h:hq_h + hq_crop_size, hq_w:hq_w + hq_crop_size]\n",
        "      lq_img_cropped = tf.cast(lq_img_cropped,dtype=tf.float32)/255.\n",
        "      hq_img_cropped = tf.cast(hq_img_cropped,dtype=tf.float32)/255.\n",
        "\n",
        "      return lq_img_cropped, hq_img_cropped\n",
        "\n",
        "  train_lq = tf.data.Dataset.from_generator(lq_train, output_types=(tf.uint8))\n",
        "  train_hq = tf.data.Dataset.from_generator(hq_train, output_types=(tf.uint8))\n",
        "  train_ds = tf.data.Dataset.zip((train_lq,train_hq))\n",
        "  train_ds = train_ds.shuffle(buffer_size=len(train_gt),reshuffle_each_iteration=True)\n",
        "  train_ds = train_ds.map(lambda lq,hq: random_crop(lq, hq, scale=1), num_parallel_calls=AUTOTUNE)\n",
        "  \n",
        "  train_ds = train_ds.repeat()\n",
        "  train_ds = train_ds.batch(batch_size=config.batch_shape[0])\n",
        "  train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return train_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adq79hlVpzG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell will change drastically in a future update\n",
        "def get_test_data():\n",
        "  # dataset API and augmentation\n",
        "  def hq_test():\n",
        "      for img in test_gt:\n",
        "          yield img\n",
        "  def _map_fn_hq(img):\n",
        "      hq_patch = img/255.\n",
        "      return hq_patch\n",
        "  def lq_test():\n",
        "    for img in test_input:\n",
        "      yield img\n",
        "  def _map_fn_lq(img):\n",
        "    lq_patch = img/255.\n",
        "    return lq_patch\n",
        "  test_lq = tf.data.Dataset.from_generator(lq_test, output_types=(tf.float32))\n",
        "  test_lq = test_lq.map(_map_fn_lq, num_parallel_calls=AUTOTUNE)\n",
        "  test_hq = tf.data.Dataset.from_generator(hq_test, output_types=(tf.float32))\n",
        "  test_hq = test_hq.map(_map_fn_hq, num_parallel_calls=AUTOTUNE)\n",
        "  test_ds = tf.data.Dataset.zip((test_lq,test_hq))\n",
        "  test_ds = test_ds.shuffle(buffer_size=len(test_gt),reshuffle_each_iteration=True)\n",
        "  test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  test_ds = test_ds.batch(batch_size=Tconfig.batch_shape[0])\n",
        "  return test_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6BJFRuCXUWO",
        "colab_type": "text"
      },
      "source": [
        "# Execute Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEtLoVYvddXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_time = time.time()\n",
        "train_ds = get_train_data()\n",
        "trainval_ds = get_test_data()\n",
        "load_time = time.time()-load_time\n",
        "if(Tconfig.batch_shape[0]<config.display_samples):\n",
        "  config.display_samples = Tconfig.batch_shape[0]\n",
        "config.steps_total = math.ceil(len(train_gt)/config.batch_shape[0])\n",
        "Tconfig.file_count = len(test_input)\n",
        "print('tf dataset creation time = {}'.format(load_time))\n",
        "print('Steps per epoch = {}'.format(config.steps_total))\n",
        "print('Test file count = {}'.format(Tconfig.file_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7uJLLYhgyLT",
        "colab_type": "text"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cvFv9wQWL0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def depth_to_space(scale):\n",
        "    return lambda x: tf.nn.depth_to_space(x, scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30bAYwUTWTcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def space_to_depth(block_size):\n",
        "    return lambda x: tf.nn.space_to_depth(x, block_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ziDi9BaIsIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_relu(x, filters, kernel, use_bias = True, dilation_rate=1):\n",
        "\tif dilation_rate == 0:\n",
        "\t\ty = tf.keras.layers.Conv2D(filters,1,padding='same',use_bias=use_bias,\n",
        "\t\t\tactivation='relu')(x)\n",
        "\telse:\n",
        "\t\ty = tf.keras.layers.Conv2D(filters,kernel,padding='same',use_bias=use_bias,\n",
        "\t\t\tdilation_rate=dilation_rate,\n",
        "\t\t\tactivation='relu')(x)\n",
        "\treturn y\n",
        "def conv(x, filters, kernel, use_bias=True, dilation_rate=1):\n",
        "\ty = tf.keras.layers.Conv2D(filters,kernel,padding='same',use_bias=use_bias,\n",
        "\t\tdilation_rate=dilation_rate)(x)\n",
        "\treturn y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msgDHLmsKCRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DWT(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, **kwargs):\n",
        "\t\tsuper(DWT, self).__init__(**kwargs)\n",
        "\n",
        "\tdef call(self, inputs, **kwargs):\n",
        "\t\tx01 = inputs[:,0::2,:,:] / 4.0\n",
        "\t\tx02 = inputs[:,1::2,:,:] / 4.0\n",
        "\t\tx1 = x01[:,:,0::2,:]\n",
        "\t\tx2 = x01[:,:,1::2,:]\n",
        "\t\tx3 = x02[:,:,0::2,:]\n",
        "\t\tx4 = x02[:,:,1::2,:]\n",
        "\t\ty1 = x1+x2+x3+x4\n",
        "\t\ty2 = x1-x2+x3-x4\n",
        "\t\ty3 = x1+x2-x3-x4\n",
        "\t\ty4 = x1-x2-x3+x4\n",
        "\t\ty = tf.keras.backend.concatenate([y1,y2,y3,y4],axis=-1)\n",
        "\t\treturn y\n",
        "\n",
        "\tdef compute_output_shape(self, input_shape):\n",
        "\t\tc = input_shape[-1]*4\n",
        "\t\tif(input_shape[1] != None and input_shape[2] != None):\n",
        "\t\t\treturn (input_shape[0], input_shape[1] >> 1, input_shape[2] >> 1, c)\n",
        "\t\telse:\n",
        "\t\t\treturn (None, None, None, c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZtjMVHgKJEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IWT(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, **kwargs):\n",
        "\t\tsuper(IWT, self).__init__(**kwargs)\n",
        "\n",
        "\tdef build(self, input_shape):\n",
        "\t\tc = input_shape[-1]\n",
        "\t\tout_c = c >> 2\n",
        "\t\tkernel = np.zeros((1,1,c,c),dtype=np.float32)\n",
        "\t\tfor i in range(0,c,4):\n",
        "\t\t\tidx = i >> 2\n",
        "\t\t\tkernel[0,0,idx::out_c,idx]         = [1, 1, 1, 1]\n",
        "\t\t\tkernel[0,0,idx::out_c,idx+out_c]   = [1,-1, 1,-1]\n",
        "\t\t\tkernel[0,0,idx::out_c,idx+out_c*2] = [1, 1,-1,-1]\n",
        "\t\t\tkernel[0,0,idx::out_c,idx+out_c*3] = [1,-1,-1, 1]\n",
        "\t\tself.kernel = tf.keras.backend.variable(value = kernel, dtype='float32')\n",
        "\n",
        "\tdef call(self, inputs, **kwargs):\n",
        "\t\ty = tf.keras.backend.conv2d(inputs, self.kernel, padding='same')\n",
        "\t\ty = tf.nn.depth_to_space(y,2)\n",
        "\t\treturn y\n",
        "\n",
        "\tdef compute_output_shape(self, input_shape):\n",
        "\t\tc = input_shape[-1]>>2\n",
        "\t\tif(input_shape[1] != None and input_shape[2] != None):\n",
        "\t\t\treturn (input_shape[0], input_shape[1] << 1, input_shape[2] << 1, c)\n",
        "\t\telse:\n",
        "\t\t\treturn (None, None, None, c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SKrYMthLwlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pyramid(x, filters, Pyramid_Cells):\n",
        "\tdef pyramid_cell(x, filters, dilation_rates):\n",
        "\t\tfor i in range(len(dilation_rates)):\n",
        "\t\t\tdilation_rate = dilation_rates[i]\n",
        "\t\t\tif i==0:\n",
        "\t\t\t\tt = conv_relu(x,filters,3,dilation_rate=dilation_rate)\n",
        "\t\t\t\t_t = tf.keras.layers.Concatenate(axis=-1)([x,t])\n",
        "\t\t\telse:\n",
        "\t\t\t\tt = conv_relu(_t,filters,3,dilation_rate=dilation_rate)\n",
        "\t\t\t\t_t = tf.keras.layers.Concatenate(axis=-1)([_t,t])\n",
        "\t\treturn _t\n",
        "\tconcat_list = []\n",
        "\tt = conv_relu(x,filters*2,3)\n",
        "\tfor i in range(len(Pyramid_Cells)):\n",
        "\t\tif i == 0:\n",
        "\t\t\t_t = pyramid_cell(t,filters,Pyramid_Cells[i])\n",
        "\t\telse:\n",
        "\t\t\t_t = pyramid_cell(_t,filters,Pyramid_Cells[i])\n",
        "\t\t_t = conv_relu(_t,filters,1)\n",
        "\t\tconcat_list.append(_t)\t\t\n",
        "\tif len(concat_list) == 1:\n",
        "\t\treturn _t\n",
        "\telse:\n",
        "\t\ty = tf.keras.layers.Concatenate(axis=-1)(concat_list)\n",
        "\t\treturn y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc5zc58tLzE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(x,nFilters, nPyramids, Pyramid_Cells, nPyramidFilters,type):\n",
        "\tdef pyramid(x,nFilters,Pyramid_Cells,nPyramidFilters):\n",
        "\t\t_t = pyramid(x, nPyramidFilters, Pyramid_Cells)\t\t\n",
        "\t\ty = conv(_t, nFilters, 3)\n",
        "\t\ty = tf.keras.layers.Lambda(lambda x:x*0.1)(y)\n",
        "\t\ty = tf.keras.layers.Add()([x,y])\n",
        "\t\treturn y\t\n",
        "\tif(type=='wavelet'):\n",
        "\t\tx = DWT()(x)\n",
        "\tt = Lambda(space_to_depth(block_size=2))(x)\n",
        "\tt = conv_relu(t,nFilters,5)\n",
        "\tt = conv_relu(t,nFilters,3)\n",
        "\tt = pyramid(t,nFilters,Pyramid_Cells,nPyramidFilters)\n",
        "\tt = tf.keras.layers.Conv2D(nFilters*2,5,padding='same',strides = (2,2),use_bias=True)(t)\n",
        "\tt = pyramid(t,nFilters*2,Pyramid_Cells,nPyramidFilters*2)\n",
        "\tt = tf.keras.layers.Conv2D(nFilters*4,5,padding='same',strides = (2,2),use_bias=True)(t)\n",
        "\tt = pyramid(t,nFilters*4,Pyramid_Cells,nPyramidFilters*4)\n",
        "\treturn t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alDrMyflL_wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(x,nFilters, nPyramids, Pyramid_Cells, nPyramidFilters,type):\n",
        "  def pyramid(x,nFilters,Pyramid_Cells,nPyramidFilters):\n",
        "    _t = pyramid(x, nPyramidFilters, Pyramid_Cells)\t\t\n",
        "    y = conv(_t, nFilters, 3)\n",
        "    y = tf.keras.layers.Lambda(lambda x:x*0.1)(y)\n",
        "    y = tf.keras.layers.Add()([x,y])\n",
        "    return y\n",
        "  t = pyramid(x,nFilters,Pyramid_Cells,nPyramidFilters)\n",
        "  t = tf.keras.layers.Conv2DTranspose(nFilters/2,4,strides=(2,2),padding='same',use_bias=True)(t)\n",
        "  t = pyramid(t,nFilters/2,Pyramid_Cells,nPyramidFilters/2)\n",
        "  t = tf.keras.layers.Conv2DTranspose(nFilters/4,4,strides=(2,2),padding='same',use_bias=True)(t)\n",
        "  t = pyramid(t,nFilters/4,Pyramid_Cells,nPyramidFilters/4)\n",
        "  t = Lambda(depth_to_space(scale=2))(t)\n",
        "  if(type=='wavelet'):\n",
        "    out = conv(t,3*4,3)\n",
        "    out = IWT()(out)\n",
        "  else:\n",
        "    out = conv(t,3,3) \n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBlrO6IYMFJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(nPyramids,Pyramid_Cells,nFilters,nFilters_deco,nPyramidFilters,nPyramidFilters_deco):\n",
        "  x = tf.keras.layers.Input(shape=(None, None, 3))\n",
        "  w = encoder(x,nFilters, nPyramids, Pyramid_Cells, nPyramidFilters,type='wavelet')\n",
        "  out = decoder(w,nFilters_deco, nPyramids, Pyramid_Cells, nPyramidFilters_deco,type='wavelet')\n",
        "  return tf.keras.Model(x,out,name=\"generator\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjDDqVAfg1p-",
        "colab_type": "text"
      },
      "source": [
        "# Training Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxcNUXNJDadO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Charbonnier Loss\n",
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None,config.batch_shape[1],config.batch_shape[2],config.batch_shape[3]], dtype=tf.float32),tf.TensorSpec(shape=[None,config.batch_shape[1],config.batch_shape[2],config.batch_shape[3]], dtype=tf.float32)))\n",
        "def charbonnier(y_true, y_pred):\n",
        "    epsilon = 1e-3\n",
        "    error = y_true - y_pred\n",
        "    p = tf.keras.backend.sqrt(tf.keras.backend.square(error) + tf.keras.backend.square(epsilon))\n",
        "    return tf.keras.backend.mean(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wY2J8Eadr6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None,config.batch_shape[1],config.batch_shape[2],config.batch_shape[3]], dtype=tf.float32),tf.TensorSpec(shape=[None,config.batch_shape[1],config.batch_shape[2],config.batch_shape[3]], dtype=tf.float32)))\n",
        "def calculate_loss(target_batch,gen_out):\n",
        "  mse_loss = config.weight_mse_loss*tf.reduce_mean(tf.keras.losses.MeanSquaredError()(target_batch,gen_out))\n",
        "  # char_loss = config.weight_char_loss*charbonnier(target_batch, gen_out\n",
        "  return mse_loss # + char_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VWvTra1g4Gw",
        "colab_type": "text"
      },
      "source": [
        "# Train & Test Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scV_gcHndvfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None,config.batch_shape[1],config.batch_shape[2],config.batch_shape[3]], dtype=tf.float32),tf.TensorSpec(shape=[None,config.batch_shape[1],config.batch_shape[2],config.batch_shape[3]], dtype=tf.float32)))\n",
        "def train_step(input_batch,target_batch):\n",
        "  global optimizer, model\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    gen_out = model(input_batch,training=True)\n",
        "    mse_loss = calculate_loss(target_batch,gen_out)\n",
        "  del input_batch,gen_out,target_batch\n",
        "  gradients = tape.gradient(mse_loss, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "  return mse_loss\n",
        "\n",
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None,None,None,Tconfig.batch_shape[3]], dtype=tf.float32),tf.TensorSpec(shape=[None,None,None,Tconfig.batch_shape[3]], dtype=tf.float32)))\n",
        "def test_step(input_batch,target_batch):\n",
        "  global model\n",
        "  gen_out = model(input_batch,training=False)\n",
        "  return gen_out,tf.reduce_sum(tf.image.psnr(tf.image.convert_image_dtype(gen_out, tf.dtypes.uint8, saturate=True),tf.image.convert_image_dtype(target_batch, tf.dtypes.uint8, saturate=True),max_val=255))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNZ7b3kGg7m-",
        "colab_type": "text"
      },
      "source": [
        "# Save Model & Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grq630pNdxAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(traintest_psnr):\n",
        "  global ckpt, chkpt_manager_best, chkpt_manager_latest\n",
        "  chkpt_manager_latest.save(checkpoint_number=1)\n",
        "  model.save_weights(config.save_model_dir+'/latest_model.hdf5')\n",
        "  if(traintest_psnr >= ckpt.max_psnr):\n",
        "    ckpt.max_psnr.assign(traintest_psnr)\n",
        "    chkpt_manager_best.save(checkpoint_number=1)\n",
        "    model.save_weights(config.save_model_dir+'/best_model.hdf5')\n",
        "  return\n",
        "\n",
        "gap_img = tf.constant(np.zeros([Tconfig.batch_shape[1],20,3], dtype = np.float32))\n",
        "def save_sample_predictions(epoch,input_batch,gen_out,target_batch):\n",
        "  if(epoch % config.display_freq == 0):\n",
        "    tf.io.gfile.makedirs(config.save_image_dir+'/{}'.format(epoch))\n",
        "    for i in range(config.display_samples):\n",
        "      # disp_img = tf.concat([input_batch[i], gap_img, gen_out[i], gap_img, target_batch[i]], axis=1) # if a gap is needed b/w images, uncomment this and comment next ine. Note that the image height must be set in test config for this to work.\n",
        "      disp_img = tf.concat([input_batch[i], gen_out[i], target_batch[i]], axis=1)\n",
        "      disp_img = tf.image.convert_image_dtype(disp_img, tf.dtypes.uint8, saturate=True).numpy()\n",
        "      imageio.imwrite(config.save_image_dir+'/{}/{}.png'.format(epoch,i),disp_img)\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMmYG_hUg_-A",
        "colab_type": "text"
      },
      "source": [
        "# Instantiate Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HBlexb5qn_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Pyramid_Cells = ((3,2,1,1,1,1),)\n",
        "nPyramids = 1\n",
        "schedule=None\n",
        "optimizer=None\n",
        "model=None\n",
        "ckpt=None\n",
        "chkpt_manager_latest=None\n",
        "chkpt_manager_best=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSWYzkNydxzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def instantiate_training_variables():\n",
        "  global schedule,optimizer,model,ckpt,chkpt_manager_latest,chkpt_manager_best\n",
        "  schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[3000*config.steps_total,5000*config.steps_total], values=[1e-4,0.5e-4,0.2e-4])\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=schedule)\n",
        "  model = get_model(nPyramids,Pyramid_Cells,nFilters=16,nFilters_deco=64,nPyramidFilters=16,nPyramidFilters_deco=64)\n",
        "  ckpt = tf.train.Checkpoint(epoch = tf.Variable(0), max_psnr = tf.Variable(0.0), optimizer=optimizer)\n",
        "  chkpt_manager_latest = tf.train.CheckpointManager(ckpt, config.log_dir+'/latest_chkpt', max_to_keep=1,checkpoint_name='ckpt')\n",
        "  chkpt_manager_best = tf.train.CheckpointManager(ckpt, config.log_dir+'/best_chkpt', max_to_keep=1,checkpoint_name='ckpt')\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dF-_nkLhEhx",
        "colab_type": "text"
      },
      "source": [
        "# Load Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smcgf9a-dyeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def restore_checkpoint(training_mode):\n",
        "  global model,ckpt,chkpt_manager_best,chkpt_manager_latest\n",
        "  if(training_mode=='best'):\n",
        "      ckpt.restore(chkpt_manager_best.latest_checkpoint)\n",
        "      model.load_weights(config.save_model_dir+'/best_model.hdf5')\n",
        "      print(\"Checkpoint restored from epoch {}\".format(ckpt.epoch.numpy()))\n",
        "  elif(training_mode=='latest'):\n",
        "    if(tf.io.gfile.exists(config.log_dir+'/latest_chkpt')):\n",
        "      ckpt.restore(chkpt_manager_latest.latest_checkpoint)\n",
        "      model.load_weights(config.save_model_dir+'/latest_model.hdf5')\n",
        "      print(\"Checkpoint restored from epoch {}\".format(ckpt.epoch.numpy()))\n",
        "    else:\n",
        "      print(\"Created new checkpoint\")\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCSfWVsGhH8S",
        "colab_type": "text"
      },
      "source": [
        "# Create/Update Log File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APHeObzYd7CJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_log_files():\n",
        "\n",
        "  global ckpt\n",
        "\n",
        "  def trim_log_file(fileName, epoch):\n",
        "    with open(fileName,'r') as f:\n",
        "      records = [line.rstrip() for line in f]\n",
        "      while(True):\n",
        "        if(int(records[-1].split(',')[0])>epoch):\n",
        "          records.remove(records[-1])\n",
        "        else:\n",
        "          break\n",
        "\n",
        "    with open(fileName+'','w') as f:\n",
        "      f.write('\\n'.join(records)+'\\n')\n",
        "\n",
        "  if(ckpt.epoch==0):\n",
        "    log_file = open(config.log_dir+\"/log_file_loss.csv\",\"w\")\n",
        "    log_file.write('{},{},{},{}\\n'.format('Epoch','Step','step time','MSE loss'))\n",
        "    log_file.close()\n",
        "\n",
        "    log_file = open(config.log_dir+\"/log_file_accuracy.csv\",\"w\")\n",
        "    log_file.write('{},{}\\n'.format('Epoch','traintest_psnr'))\n",
        "    log_file.close()\n",
        "\n",
        "  else:\n",
        "\n",
        "    if(not os.path.exists(config.log_dir+\"/log_file_loss.csv\")):\n",
        "      log_file = open(config.log_dir+\"/log_file_loss.csv\",\"w\")\n",
        "      log_file.write('{},{},{},{}\\n'.format('Epoch','Step','step time','MSE loss'))\n",
        "      log_file.close()\n",
        "    else:\n",
        "      trim_log_file(config.log_dir+\"/log_file_loss.csv\",ckpt.epoch.numpy())\n",
        "\n",
        "    if(not os.path.exists(config.log_dir+\"/log_file_accuracy.csv\")):\n",
        "      log_file = open(config.log_dir+\"/log_file_accuracy.csv\",\"w\")\n",
        "      log_file.write('{},{}\\n'.format('Epoch','traintest_psnr'))\n",
        "      log_file.close()\n",
        "    else:\n",
        "      trim_log_file(config.log_dir+\"/log_file_accuracy.csv\",ckpt.epoch.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rhPge6XhMls",
        "colab_type": "text"
      },
      "source": [
        "# Plot Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDCrxmc6GQGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_training_metrics():\n",
        "  with open(config.log_dir+'/log_file_loss.csv') as f:\n",
        "    rows = [line.rstrip().split(\",\") for line in f]\n",
        "  mse_loss = []\n",
        "  for row in rows[1:]:\n",
        "    mse_loss.append(float(row[3]))  # mse loss\n",
        "  plt.plot(mse_loss)\n",
        "  plt.ylabel('loss per step')\n",
        "  plt.xlabel('Step')\n",
        "  plt.title('MSE loss')\n",
        "  plt.grid()\n",
        "  plt.savefig(config.log_dir+'/MSE_loss.png',dpi=500)\n",
        "  plt.close()\n",
        "\n",
        "  with open(config.log_dir+'/log_file_accuracy.csv') as f:\n",
        "    rows = [line.rstrip().split(\",\") for line in f]\n",
        "  accuracy = []\n",
        "  for row in rows[1:]:\n",
        "    accuracy.append(float(row[1]))  # PSNR\n",
        "  plt.plot(accuracy)\n",
        "  plt.ylabel('PSNR')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.title('Accuracy')\n",
        "  plt.grid()\n",
        "  plt.savefig(config.log_dir+'/psnr.png',dpi=500)\n",
        "  plt.close()\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk2IF9sKhQoz",
        "colab_type": "text"
      },
      "source": [
        "# Training Routine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sLb_dMtQ7Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(training_mode):\n",
        "  global ckpt\n",
        "  global model\n",
        "  global chkpt_manager_latest\n",
        "\n",
        "  step_time = 0.0\n",
        "  print_template = 'Epoch: {}, step: {}, time: {:.3f}s, mse_loss: {:.5f}'\n",
        "\n",
        "  instantiate_training_variables()\n",
        "  restore_checkpoint(training_mode)\n",
        "  create_log_files()\n",
        "  plot_model(model, to_file = config.save_model_dir+'/g_model.png', show_shapes=True, show_layer_names=True)\n",
        "    \n",
        "  ckpt.epoch.assign_add(1)\n",
        "  print('learning rate = {}'.format(ckpt.optimizer._decayed_lr(tf.float32)))\n",
        "  log_file = open(config.log_dir+\"/log_file_loss.csv\",\"a\")\n",
        "  for step,(input_batch,target_batch) in enumerate(train_ds,start=1):\n",
        "    epoch_step = step%config.steps_total\n",
        "    step_time = time.time()  \n",
        "    mse_loss = train_step(input_batch,target_batch)\n",
        "    step_time = time.time()-step_time\n",
        "    log_file.write('{},{},{},{}\\n'.format(ckpt.epoch.numpy(),epoch_step,step_time,mse_loss))\n",
        "    # print(print_template.format(ckpt.epoch.numpy(),epoch_step,step_time,mse_loss))  # uncomment for stepwise training progress. Be warned, this would result in browser crash after a lot of iterations if you are using jupyter/colab etc.\n",
        "\n",
        "    if(epoch_step==0):\n",
        "      log_file.close()\n",
        "      traintest_psnr = 0.0\n",
        "      for input_batch,target_batch in trainval_ds:\n",
        "        gen_out,minibatch_psnr = test_step(input_batch,target_batch)\n",
        "        traintest_psnr+=minibatch_psnr\n",
        "      traintest_psnr=traintest_psnr/Tconfig.file_count\n",
        "      save_model(traintest_psnr)\n",
        "      save_sample_predictions(ckpt.epoch.numpy(),input_batch,gen_out,target_batch)\n",
        "      log_file = open(config.log_dir+\"/log_file_accuracy.csv\",\"a\")\n",
        "      log_file.write('{},{}\\n'.format(ckpt.epoch.numpy(),traintest_psnr))\n",
        "      log_file.close()\n",
        "      chkpt_manager_latest.save(checkpoint_number=1)\n",
        "      model.save_weights(config.save_model_dir+'/latest_model.hdf5')\n",
        "      print('Checkpoint saved')\n",
        "      ckpt.epoch.assign_add(1)\n",
        "      log_file = open(config.log_dir+\"/log_file_loss.csv\",\"a\")\n",
        "      if(ckpt.epoch.numpy()%config.plot_training_freq==0):\n",
        "        plot_training_metrics()\n",
        "      if(ckpt.epoch.numpy()%config.progress_freq==0):\n",
        "        print('Epoch = {}, max_psnr = {}, current psnr = {}'.format(ckpt.epoch.numpy(), ckpt.max_psnr.numpy(), traintest_psnr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdPmmpqkeAWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train('latest') # 'latest' => resume from latest weights, 'best => resume from best psnr epoch. When training from scratch, always pass latest as argument here."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
